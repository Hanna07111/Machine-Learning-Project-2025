{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-22T09:35:06.371211Z",
     "start_time": "2025-11-22T09:35:05.650066Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_recall_curve, auc, classification_report\n",
    "from xgboost import XGBClassifier"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:35:06.448038Z",
     "start_time": "2025-11-22T09:35:06.374958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(\"../../../dataset/open_world/openworld_train.csv\")\n",
    "test_df  = pd.read_csv(\"../../../dataset/open_world/openworld_test.csv\")"
   ],
   "id": "3aaed509bd2ca94c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:35:06.459347Z",
     "start_time": "2025-11-22T09:35:06.451604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# feature/label 분리\n",
    "target_col = train_df.columns[-1]   # 마지막 컬럼이 label\n",
    "\n",
    "# open-world label 통합\n",
    "train_df[target_col] = train_df[target_col].apply(lambda x: 0 if x == 95 else 1)\n",
    "test_df[target_col]  = test_df[target_col].apply(lambda x: 0 if x == 95 else 1)\n",
    "\n",
    "X_train = train_df.drop(columns=[target_col]).values\n",
    "y_train = train_df[target_col].astype(np.float32).values\n",
    "X_test  = test_df.drop(columns=[target_col]).values\n",
    "y_test  = test_df[target_col].astype(np.float32).values"
   ],
   "id": "2bcd8cd1c6f682ad",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:36:09.068108Z",
     "start_time": "2025-11-22T09:35:06.462441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Best MLP param.\n",
    "best_mlp_params = {\n",
    "    \"hidden_layer_sizes\": (288, 80),\n",
    "    \"alpha\": 3.813848083517318e-05,\n",
    "    \"learning_rate_init\": 0.0017053755428803074,\n",
    "    \"batch_size\": 128,\n",
    "    \"activation\": \"relu\",\n",
    "    \"solver\": \"adam\",\n",
    "}\n",
    "\n",
    "# Train MLP ensemble (seeds: 0-4)\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "mlp_models = []\n",
    "\n",
    "print(\"\\nTraining 5 MLP models...\")\n",
    "for s in seeds:\n",
    "    mlp = MLPClassifier(\n",
    "        **best_mlp_params,\n",
    "        random_state=s,\n",
    "        max_iter=50\n",
    "    )\n",
    "    mlp.fit(X_train, y_train)\n",
    "    mlp_models.append(mlp)\n",
    "    print(f\"MLP model seed={s} done.\")"
   ],
   "id": "54f145c30bef697d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training 5 MLP models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py3_8_11/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model seed=0 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py3_8_11/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model seed=1 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py3_8_11/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model seed=2 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py3_8_11/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model seed=3 done.\n",
      "MLP model seed=4 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py3_8_11/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:36:10.759858Z",
     "start_time": "2025-11-22T09:36:09.076898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train XGBoost Model\n",
    "xgb_params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": 10,\n",
    "    \"learning_rate\": 0.1890408241426905,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"subsample\": 0.8887320375513359,\n",
    "    \"colsample_bytree\": 0.9912853863634461,\n",
    "    \"gamma\": 0.014498503088113818,\n",
    "    \"reg_lambda\": 2.7498279931612504,\n",
    "    \"reg_alpha\": 0.0985171472007404,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "print(\"\\nTraining XGBoost model (fill your own params in xgb_params)...\")\n",
    "xgb_model = XGBClassifier(\n",
    "    **xgb_params,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"\\nTraining XGBoost model (fill your own params in xgb_params)...\")\n",
    "xgb_model = XGBClassifier(\n",
    "    **xgb_params,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"XGBoost training done.\")"
   ],
   "id": "9244156f9f1277e8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py3_8_11/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [18:36:09] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1724807611129/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost model (fill your own params in xgb_params)...\n",
      "\n",
      "Training XGBoost model (fill your own params in xgb_params)...\n",
      "XGBoost training done.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:36:10.845509Z",
     "start_time": "2025-11-22T09:36:10.763050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Soft-Voting Ensemble (MLP x5 + XGBoost)\n",
    "print(\"\\nEnsembling predictions...\")\n",
    "\n",
    "proba_list = []\n",
    "\n",
    "# MLP 5개 확률\n",
    "for model in mlp_models:\n",
    "    p = model.predict_proba(X_test)[:, 1]\n",
    "    proba_list.append(p)\n",
    "\n",
    "# XGBoost 확률\n",
    "xgb_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "proba_list.append(xgb_proba)\n",
    "\n",
    "# 평균 확률 (soft voting)\n",
    "proba_ensemble = np.mean(proba_list, axis=0)\n",
    "y_pred = (proba_ensemble >= 0.5).astype(int)"
   ],
   "id": "182aa85d8ba7a5c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensembling predictions...\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:36:10.874084Z",
     "start_time": "2025-11-22T09:36:10.854022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluation\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "test_f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "test_f1_micro = f1_score(y_test, y_pred, average=\"micro\")\n",
    "test_f1_weighted = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "# ROC-AUC\n",
    "test_roc_auc = roc_auc_score(y_test, proba_ensemble)\n",
    "\n",
    "# PR-AUC\n",
    "prec, rec, _ = precision_recall_curve(y_test, proba_ensemble)\n",
    "test_pr_auc = auc(rec, prec)\n",
    "\n",
    "print(\"\\n========== [TEST RESULTS - MLP5 + XGBoost Ensemble] ==========\")\n",
    "print(f\"Accuracy        : {test_acc:.4f}\")\n",
    "print(f\"F1 (macro)      : {test_f1_macro:.4f}\")\n",
    "print(f\"F1 (micro)      : {test_f1_micro:.4f}\")\n",
    "print(f\"F1 (weighted)   : {test_f1_weighted:.4f}\")\n",
    "print(f\"ROC-AUC         : {test_roc_auc:.4f}\")\n",
    "print(f\"PR-AUC          : {test_pr_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ],
   "id": "eee1080639ede27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== [TEST RESULTS - MLP5 + XGBoost Ensemble] ==========\n",
      "Accuracy        : 0.8980\n",
      "F1 (macro)      : 0.8851\n",
      "F1 (micro)      : 0.8980\n",
      "F1 (weighted)   : 0.8971\n",
      "ROC-AUC         : 0.9579\n",
      "PR-AUC          : 0.9761\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8796    0.8160    0.8466      3000\n",
      "         1.0     0.9067    0.9412    0.9236      5700\n",
      "\n",
      "    accuracy                         0.8980      8700\n",
      "   macro avg     0.8932    0.8786    0.8851      8700\n",
      "weighted avg     0.8974    0.8980    0.8971      8700\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
